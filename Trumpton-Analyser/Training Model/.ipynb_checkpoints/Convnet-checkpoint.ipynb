{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reference: http://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
    "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "# file imports\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model 1, model with a single validation split\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(3, img_width, img_height)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "# print model.shape()\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.00001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import listdir\n",
    "from PIL import Image as PImage\n",
    "\n",
    "def loadImages(path):\n",
    "    # return array of images\n",
    "    print path\n",
    "    imagesList = listdir(path)\n",
    "#     print \"image list:\" + str(imagesList)\n",
    "    loadedImages = []\n",
    "    for image in imagesList:\n",
    "        img1 = PImage.open(path +'/'+ image)\n",
    "        img = img1.copy()\n",
    "        img1.close()\n",
    "        loadedImages.append(img)\n",
    "\n",
    "    return loadedImages\n",
    "\n",
    "path = \"train1/trump\"\n",
    "path2 = \"test/trump\"\n",
    "# your images in an array\n",
    "imgs = loadImages(path)\n",
    "# print imgs\n",
    "img=list(np.asarray(imgs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "X_test = []\n",
    "for img in imgs:\n",
    "    X_train.append(np.asarray(img))\n",
    "# for img in imgs2:\n",
    "#     X_test.append(np.asarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(X_train)\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train=[]\n",
    "Y_test=[]\n",
    "Y_train1=[]\n",
    "for i in xrange(len(X_train)):\n",
    "    Y_train.append(np.array([1,0,0]))\n",
    "#     Y_train1.append(np.array[1])\n",
    "    \n",
    "# for i in xrange(len(X_test)):\n",
    "#     Y_test.append(np.array([1,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs = loadImages('train1/hillary')\n",
    "for img in imgs:\n",
    "    X_train.append(np.asarray(img))\n",
    "    \n",
    "imgs2 = loadImages('test/hillary')\n",
    "# for img in imgs2:\n",
    "#     X_test.append(np.asarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in xrange(len(imgs)):\n",
    "    Y_train.append(np.array([0,1,0]))\n",
    "    \n",
    "# for i in xrange(len(imgs2)):\n",
    "#     Y_test.append(np.array([0,1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path='train1/none'\n",
    "imgs = loadImages(path)\n",
    "for img in imgs:\n",
    "    X_train.append(np.asarray(img))\n",
    "for i in xrange(len(imgs)):\n",
    "    Y_train.append(np.array([0,0,1]))\n",
    "    \n",
    "# path='test/none'\n",
    "# imgs2 = loadImages(path)\n",
    "# for img in imgs2:\n",
    "#     X_test.append(np.asarray(img))\n",
    "# for i in xrange(len(imgs2)):\n",
    "#     Y_test.append(np.array([0,0,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(len(X_train)):\n",
    "    X_train[i]=np.swapaxes(X_train[i],2,0)\n",
    "\n",
    "# \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in xrange(len(X_test)):\n",
    "#     X_test[i]=np.swapaxes(X_test[i],2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train[0].shape\n",
    "# X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "Y_train=np.array(Y_train)\n",
    "X_test=np.array(X_test)\n",
    "Y_test=np.array(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, nb_epoch=100, batch_size=100,\n",
    "             validation_split=0.1,shuffle=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('try_6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model_without_cross_validation.h5')\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print X_train[0:10]\n",
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = load_model('model_cross_validation.h5')\n",
    "model.load_weights('try_cross_validation.h5')\n",
    "y = np.expand_dims(X_train[1500], axis=0)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = load_model('model_cross_validation.h5')\n",
    "model.load_weights('try_cross_validation.h5')\n",
    "a = model.predict( X_train, batch_size=32, verbose=1)\n",
    "# print y_tes\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print Y_train[1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_train, Y_train, batch_size=32, verbose=1, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model with cross validation (Model 2)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import sklearn\n",
    "# from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "import numpy\n",
    "kfold = StratifiedShuffleSplit(Y_train, 10, test_size=0.5, random_state=0)\n",
    "\n",
    "cvscores = []\n",
    "for train, test in kfold:\n",
    "  # create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 3, 3, input_shape=(3, img_width, img_height)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(32, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    # model.add(Dropout(0.5))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    # print model.shape()\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = SGD(lr=0.00001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train[train], Y_train[train], nb_epoch=150, batch_size=100, verbose=1)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X_train[test], Y_train[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('try_cross_validation.h5')\n",
    "model.save('model_cross_validation.h5')\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model_cross_validation.h5')\n",
    "model.load_weights('try_cross_validation.h5')\n",
    "a= model.predict(X_train,batch_size=1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model 3, with image augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 64, 64\n",
    "\n",
    "train_data_dir = 'train/'\n",
    "validation_data_dir = 'test/'\n",
    "nb_train_samples = 1267\n",
    "nb_validation_samples = 500\n",
    "nb_epoch = 100\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(3, img_width, img_height)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "# print model.shape()\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        nb_epoch=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples)\n",
    "\n",
    "model.save_weights('gen_model_weights.h5')\n",
    "model.save('gen_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
